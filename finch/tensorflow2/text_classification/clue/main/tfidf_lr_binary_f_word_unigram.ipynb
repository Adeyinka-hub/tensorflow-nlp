{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tfidf_lr_binary_f_word_unigram.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gOCro69Hq2bd","executionInfo":{"status":"ok","timestamp":1604373382607,"user_tz":-480,"elapsed":17304,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"801d5cd2-33ae-46ab-8a35-f1b6f7f3dec0","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow2/text_classification/clue/main')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cen-pkx_qh40","executionInfo":{"status":"ok","timestamp":1604373386024,"user_tz":-480,"elapsed":6764,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"04f96d28-c8fa-47de-8a18-0d301a51351e","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install jieba"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (0.42.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AsflpquGwz_n","executionInfo":{"status":"ok","timestamp":1604373386382,"user_tz":-480,"elapsed":6311,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["import json\n","import jieba\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n","from sklearn.metrics import classification_report"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZO1lddnxeGt","executionInfo":{"status":"ok","timestamp":1604373387109,"user_tz":-480,"elapsed":721,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip()\n","      word2idx[line] = i\n","  return word2idx\n","\n","\n","def get_data():\n","  x_train = []\n","  y_train = []\n","  x_test = []\n","  y_test = []\n","\n","  with open('../data/train.txt') as f:\n","    for line in f:\n","      line = json.loads(line.rstrip())\n","      text, label = line['content'], line['label']\n","      x_train.append(''.join(list(text)))\n","      y_train.append(label2idx[line['label']])\n","\n","  with open('../data/test.txt') as f:\n","    for line in f:\n","      line = json.loads(line.rstrip())\n","      text, label = line['content'], line['label']\n","      x_test.append(''.join(list(text)))\n","      y_test.append(label2idx[line['label']])\n","\n","  return (x_train, y_train), (x_test, y_test)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKjlPoUwzvYu","executionInfo":{"status":"ok","timestamp":1604373416411,"user_tz":-480,"elapsed":30010,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"ddaa445a-2358-4ce6-b844-0c241821232f","colab":{"base_uri":"https://localhost:8080/"}},"source":["label2idx = get_vocab('../vocab/label.txt')\n","(x_train, y_train), (x_test, y_test) = get_data()\n","\n","count_model = CountVectorizer(binary = False,\n","                              ngram_range = (1,1),\n","                              tokenizer = lambda x: jieba.lcut(x))\n","count_model.fit(x_train)\n","\n","tfidf_model = TfidfTransformer()\n","tfidf_model.fit(count_model.transform(x_train))\n","X_train_tfidf = tfidf_model.transform(count_model.transform(x_train))\n","X_test_tfidf = tfidf_model.transform(count_model.transform(x_test))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n","Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.947 seconds.\n","Prefix dict has been built successfully.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wkIMtUOe1zKH","executionInfo":{"status":"ok","timestamp":1604373448506,"user_tz":-480,"elapsed":62096,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"4694913a-eb0c-493c-a905-f043038790e0","colab":{"base_uri":"https://localhost:8080/"}},"source":["lr_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n","y_pred = lr_model.fit(X_train_tfidf, y_train).predict(X_test_tfidf)\n","final_acc = (y_pred == y_test).mean()\n","print(\"Testing Accuracy: {:.3f}\".format(final_acc))\n","print('\\n'+classification_report(y_true = y_test,\n","                                 y_pred = y_pred,\n","                                 labels = list(label2idx.values()),\n","                                 target_names = list(label2idx.keys()),\n","                                 digits = 3,))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.583\n","\n","              precision    recall  f1-score   support\n","\n","     sadness      0.558     0.818     0.664      1448\n","   happiness      0.630     0.690     0.659       978\n","        like      0.663     0.369     0.474       453\n","       anger      0.469     0.255     0.330       447\n","        fear      0.647     0.164     0.262        67\n","    surprise      0.929     0.126     0.222       103\n","     disgust      0.602     0.318     0.417       471\n","\n","    accuracy                          0.583      3967\n","   macro avg      0.643     0.391     0.432      3967\n","weighted avg      0.594     0.583     0.556      3967\n","\n"],"name":"stdout"}]}]}