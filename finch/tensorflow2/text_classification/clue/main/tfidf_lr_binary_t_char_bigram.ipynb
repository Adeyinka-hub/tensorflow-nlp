{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tfidf_lr_binary_t_char_bigram.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gOCro69Hq2bd","executionInfo":{"status":"ok","timestamp":1604372676093,"user_tz":-480,"elapsed":24541,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"fd87bc13-26fb-42bf-f1ac-adb70458793d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow2/text_classification/clue/main')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AsflpquGwz_n","executionInfo":{"status":"ok","timestamp":1604372678308,"user_tz":-480,"elapsed":2203,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["import json\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n","from sklearn.metrics import classification_report"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZO1lddnxeGt","executionInfo":{"status":"ok","timestamp":1604372678311,"user_tz":-480,"elapsed":2199,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip()\n","      word2idx[line] = i\n","  return word2idx\n","\n","\n","def get_data():\n","  x_train = []\n","  y_train = []\n","  x_test = []\n","  y_test = []\n","\n","  with open('../data/train.txt') as f:\n","    for line in f:\n","      line = json.loads(line.rstrip())\n","      text, label = line['content'], line['label']\n","      x_train.append(''.join(list(text)))\n","      y_train.append(label2idx[line['label']])\n","\n","  with open('../data/test.txt') as f:\n","    for line in f:\n","      line = json.loads(line.rstrip())\n","      text, label = line['content'], line['label']\n","      x_test.append(''.join(list(text)))\n","      y_test.append(label2idx[line['label']])\n","\n","  return (x_train, y_train), (x_test, y_test)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKjlPoUwzvYu","executionInfo":{"status":"ok","timestamp":1604372690907,"user_tz":-480,"elapsed":14786,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"806cf4f8-fcb4-4dbd-e556-a4cf96e085f2","colab":{"base_uri":"https://localhost:8080/"}},"source":["label2idx = get_vocab('../vocab/label.txt')\n","(x_train, y_train), (x_test, y_test) = get_data()\n","\n","count_model = CountVectorizer(binary = True,\n","                              ngram_range = (1,2),\n","                              tokenizer = lambda x: list(x))\n","count_model.fit(x_train)\n","\n","tfidf_model = TfidfTransformer()\n","tfidf_model.fit(count_model.transform(x_train))\n","X_train_tfidf = tfidf_model.transform(count_model.transform(x_train))\n","X_test_tfidf = tfidf_model.transform(count_model.transform(x_test))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wkIMtUOe1zKH","executionInfo":{"status":"ok","timestamp":1604372806648,"user_tz":-480,"elapsed":130517,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"839e5306-8e85-4dde-aeff-c7d672661058","colab":{"base_uri":"https://localhost:8080/"}},"source":["lr_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n","y_pred = lr_model.fit(X_train_tfidf, y_train).predict(X_test_tfidf)\n","final_acc = (y_pred == y_test).mean()\n","print(\"Testing Accuracy: {:.3f}\".format(final_acc))\n","print('\\n'+classification_report(y_true = y_test,\n","                                 y_pred = y_pred,\n","                                 labels = list(label2idx.values()),\n","                                 target_names = list(label2idx.keys()),\n","                                 digits = 3,))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.591\n","\n","              precision    recall  f1-score   support\n","\n","     sadness      0.566     0.840     0.676      1448\n","   happiness      0.640     0.715     0.675       978\n","        like      0.667     0.362     0.469       453\n","       anger      0.477     0.233     0.313       447\n","        fear      0.615     0.119     0.200        67\n","    surprise      0.769     0.097     0.172       103\n","     disgust      0.605     0.306     0.406       471\n","\n","    accuracy                          0.591      3967\n","   macro avg      0.620     0.382     0.416      3967\n","weighted avg      0.597     0.591     0.558      3967\n","\n"],"name":"stdout"}]}]}